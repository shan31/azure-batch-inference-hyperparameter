{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a6d1def-9768-4fe2-934f-c170a43b9e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient, Input, Output, load_component\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.entities import Environment, ResourceConfiguration\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "from azure.ai.ml.parallel import parallel_run_function, RunFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "141856e3-8f9d-49ef-acd2-90c882288052",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4b95ac-3aae-4a2b-9ce4-6d6200f4c9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enable_node_public_ip: true\n",
      "id: /subscriptions/1a1e86ad-fe04-43a8-9dc4-0c907e547b71/resourceGroups/rg-dp100-labs/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-labs/computes/akacomputenode2\n",
      "idle_time_before_scale_down: 120\n",
      "location: eastus2\n",
      "max_instances: 2\n",
      "min_instances: 0\n",
      "name: akacomputenode2\n",
      "provisioning_state: Succeeded\n",
      "size: Standard_F4s_v2\n",
      "ssh_public_access_enabled: false\n",
      "tier: dedicated\n",
      "type: amlcompute\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get a handle to workspace\n",
    "ml_client = MLClient.from_config(credential=credential)\n",
    "\n",
    "# Retrieve an already attached Azure Machine Learning Compute.\n",
    "cpu_compute_target = \"akacomputenode2\"\n",
    "print(ml_client.compute.get(cpu_compute_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c132c45a-cd52-40ca-8cf2-1859a763681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare parallel job with run_function task\n",
    "batch_inferencing_with_mini_batch_size = parallel_run_function(\n",
    "    name=\"batch_inferencing_with_mini_batch_size\",\n",
    "    display_name=\"Batch Inferencing with mini_batch_size\",\n",
    "    description=\"parallel job to do batch inferencing with mini_batch_size on mltable tabular input\",\n",
    "    tags={\n",
    "        \"azureml_parallel_example\": \"2a_sdk\",\n",
    "    },\n",
    "    inputs=dict(\n",
    "        input_data=Input(\n",
    "            type=AssetTypes.MLTABLE,\n",
    "            description=\"Input tabular mltable data.\",\n",
    "            mode=InputOutputModes.DIRECT,  # [Important] To use mltable tabular data, it is required to use 'direct' mode.\n",
    "        ),\n",
    "        score_model=Input(\n",
    "            type=AssetTypes.URI_FOLDER,\n",
    "            description=\"Folder contains the model file.\",\n",
    "            mode=InputOutputModes.DOWNLOAD,\n",
    "        ),\n",
    "    ),\n",
    "    outputs=dict(\n",
    "        job_output_file=Output(\n",
    "            type=AssetTypes.URI_FILE,\n",
    "            mode=InputOutputModes.RW_MOUNT,\n",
    "        ),\n",
    "    ),\n",
    "    input_data=\"${{inputs.input_data}}\",  # Define which input data will be splitted into mini-batches\n",
    "    mini_batch_size=\"10kb\",  # Use 'mini_batch_size' as the data division method. For tabular input data, it split data by physical size.\n",
    "    instance_count=2,  # Use 2 nodes from compute cluster to run this parallel job.\n",
    "    max_concurrency_per_instance=1,  # Create 2 worker processors in each compute node to execute mini-batches.\n",
    "    error_threshold=5,  # Monitor the failures of item processed by the gap between mini-batch input count and returns. 'Batch inferencing' scenario should return a list, dataframe, or tuple with the successful items to try to meet this threshold.\n",
    "    mini_batch_error_threshold=5,  # Monitor the failed mini-batch by exception, time out, or null return. When failed mini-batch count is higher than this setting, the parallel job will be marked as 'failed'.\n",
    "    retry_settings=dict(\n",
    "        max_retries=2,  # Define how many retries when mini-batch execution is failed by exception, time out, or null return.\n",
    "        timeout=60,  # Define the timeout in second for each mini-batch execution.\n",
    "    ),\n",
    "    logging_level=\"DEBUG\",\n",
    "    environment_variables={\n",
    "        \"AZUREML_PARALLEL_EXAMPLE\": \"2a_sdk\",\n",
    "    },\n",
    "    task=RunFunction(\n",
    "        code=\"./script\",\n",
    "        entry_script=\"iris_prediction.py\",\n",
    "        environment=Environment(\n",
    "            image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
    "            conda_file=\"./environment/environment_parallel.yml\",\n",
    "        ),\n",
    "        program_arguments=\"--model ${{inputs.score_model}} \"  # Passthrough input model folder path into script.\n",
    "        \"--allowed_failed_percent 30 \"  # Advanced parallel setting in arguments. Visit https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-parallel-job-in-pipeline?tabs=cliv2#consider-automation-settings for more details.\n",
    "        \"--task_overhead_timeout 1200 \"\n",
    "        \"--progress_update_timeout 600 \"\n",
    "        \"--resource_monitor_interval 20 \",\n",
    "        append_row_to=\"${{outputs.job_output_file}}\",  # Define where to output the aggregated returns from each mini-batches.\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08dae3c0-37a7-48ad-93f4-4e1c42fb5897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the inputs of the job.\n",
    "input_iris_data = Input(\n",
    "    path=\"./neural-iris-mltable\", type=AssetTypes.MLTABLE, mode=InputOutputModes.DIRECT\n",
    ")\n",
    "input_model_folder = Input(\n",
    "    path=\"./iris-model\", type=AssetTypes.URI_FOLDER, mode=InputOutputModes.DOWNLOAD\n",
    ")\n",
    "\n",
    "# Declare pipeline structure.\n",
    "@pipeline(\n",
    "    display_name=\"parallel job for iris batch inferencing\",\n",
    ")\n",
    "def parallel_job_in_pipeline():\n",
    "    # Declare parallel inferencing job.\n",
    "    parallel_train = batch_inferencing_with_mini_batch_size(\n",
    "        input_data=input_iris_data,\n",
    "        score_model=input_model_folder,\n",
    "    )\n",
    "\n",
    "    # User could override parallel job run-level property when invoke that parallel job/component in pipeline.\n",
    "    parallel_train.resources.instance_count = 2\n",
    "    parallel_train.max_concurrency_per_instance = 2\n",
    "    parallel_train.mini_batch_error_threshold = 10\n",
    "    parallel_train.outputs.job_output_file.path = \"azureml://datastores/${{default_datastore}}/paths/${{name}}/aggregated_returns.csv\"\n",
    "\n",
    "\n",
    "# Create pipeline instance\n",
    "my_job = parallel_job_in_pipeline()\n",
    "\n",
    "# Set pipeline level compute\n",
    "my_job.tags.update\n",
    "my_job.settings.default_compute = \"akacomputenode2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb528e92-7401-4a7f-8783-5112476250fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display_name: parallel job for iris batch inferencing\n",
      "type: pipeline\n",
      "jobs:\n",
      "  batch_inferencing_with_mini_batch_size:\n",
      "    type: parallel\n",
      "    inputs:\n",
      "      input_data:\n",
      "        mode: direct\n",
      "        type: mltable\n",
      "        path: azureml:./neural-iris-mltable\n",
      "      score_model:\n",
      "        mode: download\n",
      "        type: uri_folder\n",
      "        path: azureml:./iris-model\n",
      "    outputs:\n",
      "      job_output_file:\n",
      "        mode: rw_mount\n",
      "        type: uri_file\n",
      "        path: azureml://datastores/${{default_datastore}}/paths/${{name}}/aggregated_returns.csv\n",
      "    resources:\n",
      "      instance_count: 2\n",
      "    error_threshold: 5\n",
      "    input_data: ${{inputs.input_data}}\n",
      "    logging_level: DEBUG\n",
      "    max_concurrency_per_instance: 2\n",
      "    mini_batch_error_threshold: 10\n",
      "    mini_batch_size: '10240'\n",
      "    retry_settings:\n",
      "      timeout: 60\n",
      "      max_retries: 2\n",
      "    task:\n",
      "      type: run_function\n",
      "      code: /mnt/batch/tasks/shared/LS_root/mounts/clusters/shanazure311/code/batch-inference/script\n",
      "      entry_script: iris_prediction.py\n",
      "      program_arguments: '--model ${{inputs.score_model}} --allowed_failed_percent\n",
      "        30 --task_overhead_timeout 1200 --progress_update_timeout 600 --resource_monitor_interval\n",
      "        20 '\n",
      "      append_row_to: ${{outputs.job_output_file}}\n",
      "      environment:\n",
      "        name: CliV2AnonymousEnvironment\n",
      "        version: d532d36cde19d44911bd81f01fe16e2f67edae9b5304fdce458d3ad681f3f244\n",
      "        image: mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\n",
      "        conda_file:\n",
      "          name: prs-env\n",
      "          channels:\n",
      "          - conda-forge\n",
      "          dependencies:\n",
      "          - python=3.7.6\n",
      "          - pip\n",
      "          - pip:\n",
      "            - mlflow\n",
      "            - mltable>=1.2.0\n",
      "            - azureml-dataset-runtime[pandas,fuse]\n",
      "            - azureml-telemetry\n",
      "            - pandas\n",
      "            - pillow\n",
      "            - azureml-core\n",
      "            - scikit-learn~=0.20.0\n",
      "            - cloudpickle==1.1.1\n",
      "    component:\n",
      "      name: batch_inferencing_with_mini_batch_size\n",
      "      display_name: Batch Inferencing with mini_batch_size\n",
      "      description: parallel job to do batch inferencing with mini_batch_size on mltable\n",
      "        tabular input\n",
      "      tags:\n",
      "        azureml_parallel_example: 2a_sdk\n",
      "      type: parallel\n",
      "      inputs:\n",
      "        input_data:\n",
      "          type: mltable\n",
      "          description: Input tabular mltable data.\n",
      "          mode: direct\n",
      "        score_model:\n",
      "          type: uri_folder\n",
      "          description: Folder contains the model file.\n",
      "          mode: download\n",
      "      outputs:\n",
      "        job_output_file:\n",
      "          type: uri_file\n",
      "          mode: rw_mount\n",
      "      resources:\n",
      "        instance_count: 2\n",
      "      error_threshold: 5\n",
      "      input_data: ${{inputs.input_data}}\n",
      "      is_deterministic: true\n",
      "      logging_level: DEBUG\n",
      "      max_concurrency_per_instance: 1\n",
      "      mini_batch_error_threshold: 5\n",
      "      mini_batch_size: '10240'\n",
      "      retry_settings:\n",
      "        timeout: 60\n",
      "        max_retries: 2\n",
      "      task:\n",
      "        type: run_function\n",
      "        code: /mnt/batch/tasks/shared/LS_root/mounts/clusters/shanazure311/code/batch-inference/script\n",
      "        entry_script: iris_prediction.py\n",
      "        program_arguments: '--model ${{inputs.score_model}} --allowed_failed_percent\n",
      "          30 --task_overhead_timeout 1200 --progress_update_timeout 600 --resource_monitor_interval\n",
      "          20 '\n",
      "        append_row_to: ${{outputs.job_output_file}}\n",
      "        environment:\n",
      "          name: CliV2AnonymousEnvironment\n",
      "          version: d532d36cde19d44911bd81f01fe16e2f67edae9b5304fdce458d3ad681f3f244\n",
      "          image: mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\n",
      "          conda_file:\n",
      "            name: prs-env\n",
      "            channels:\n",
      "            - conda-forge\n",
      "            dependencies:\n",
      "            - python=3.7.6\n",
      "            - pip\n",
      "            - pip:\n",
      "              - mlflow\n",
      "              - mltable>=1.2.0\n",
      "              - azureml-dataset-runtime[pandas,fuse]\n",
      "              - azureml-telemetry\n",
      "              - pandas\n",
      "              - pillow\n",
      "              - azureml-core\n",
      "              - scikit-learn~=0.20.0\n",
      "              - cloudpickle==1.1.1\n",
      "    environment_variables:\n",
      "      AZUREML_PARALLEL_EXAMPLE: 2a_sdk\n",
      "settings:\n",
      "  default_compute: azureml:akacomputenode2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(my_job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc7018e2-8358-454a-8cda-69a4d214c73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFileJobOutput'> and will be ignored\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>hello-world-parallel-job</td><td>careful_star_17zy9sfpgt</td><td>pipeline</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/careful_star_17zy9sfpgt?wsid=/subscriptions/1a1e86ad-fe04-43a8-9dc4-0c907e547b71/resourcegroups/rg-dp100-labs/workspaces/mlw-dp100-labs&amp;tid=4617d4c8-9c8a-4f17-b20d-6258a331c40e\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "PipelineJob({'inputs': {}, 'outputs': {}, 'jobs': {}, 'component': PipelineComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'auto_delete_setting': None, 'name': 'azureml_anonymous', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/shanazure311/code/batch-inference', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f76c957ef80>, 'version': '1', 'schema': None, 'type': 'pipeline', 'display_name': 'parallel job for iris batch inferencing', 'is_deterministic': None, 'inputs': {}, 'outputs': {}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {'batch_inferencing_with_mini_batch_size': Parallel({'init': False, 'name': 'batch_inferencing_with_mini_batch_size', 'type': 'parallel', 'status': None, 'log_files': None, 'description': None, 'tags': {'azureml_parallel_example': '2a_sdk'}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/shanazure311/code/batch-inference', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f76c957f2e0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'Batch Inferencing with mini_batch_size', 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'input_data': {'type': 'mltable', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/77a8bec4bc66b2efe852e12d96a7c17c9e926565e7e4b6f8832cd5b5ea4436be/neural-iris-mltable', 'mode': 'direct'}, 'score_model': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/83275c8626399eb007415c95523b1457c573acc8a05c4e14468ff57918d1da09/iris-model/', 'mode': 'download'}}, 'job_outputs': {'job_output_file': {'type': 'uri_file', 'path': 'azureml://datastores/${{default_datastore}}/paths/${{name}}/aggregated_returns.csv', 'mode': 'rw_mount'}}, 'inputs': {'input_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f76c957f0d0>, 'score_model': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f76c957efe0>}, 'outputs': {'job_output_file': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f76c957fca0>}, 'component': 'azureml_anonymous:9bc7f0ff-0588-48d1-bdcd-f6a5ddae8ae8', 'referenced_control_flow_node_instance_id': None, 'kwargs': {}, 'instance_id': '62d84a44-7a7c-4c6a-a64d-27f8da950a9f', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'task': {'type': 'run_function', 'code': '/subscriptions/1a1e86ad-fe04-43a8-9dc4-0c907e547b71/resourceGroups/rg-dp100-labs/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-labs/codes/aca22dd7-a5a9-41d0-9258-085e82477ca1/versions/1', 'entry_script': 'iris_prediction.py', 'program_arguments': '--model ${{inputs.score_model}} --allowed_failed_percent 30 --task_overhead_timeout 1200 --progress_update_timeout 600 --resource_monitor_interval 20 ', 'append_row_to': '${{outputs.job_output_file}}', 'environment': '/subscriptions/1a1e86ad-fe04-43a8-9dc4-0c907e547b71/resourceGroups/rg-dp100-labs/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-labs/environments/CliV2AnonymousEnvironment/versions/d532d36cde19d44911bd81f01fe16e2f67edae9b5304fdce458d3ad681f3f244'}, 'mini_batch_size': 10240, 'partition_keys': None, 'input_data': '${{inputs.input_data}}', 'retry_settings': {'timeout': 60, 'max_retries': 2}, 'logging_level': 'DEBUG', 'max_concurrency_per_instance': 2, 'error_threshold': 5, 'mini_batch_error_threshold': 10, 'resources': {'instance_count': 2}, 'environment_variables': {'AZUREML_PARALLEL_EXAMPLE': '2a_sdk'}, 'identity': None})}, 'job_types': {'parallel': 1}, 'job_sources': {'BUILDER': 1}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'NotStarted', 'log_files': None, 'name': 'careful_star_17zy9sfpgt', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/1a1e86ad-fe04-43a8-9dc4-0c907e547b71/resourceGroups/rg-dp100-labs/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-labs/jobs/careful_star_17zy9sfpgt', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/shanazure311/code/batch-inference', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f76c957ff40>, 'serialize': <msrest.serialization.Serializer object at 0x7f76c957fbb0>, 'display_name': 'parallel job for iris batch inferencing', 'experiment_name': 'hello-world-parallel-job', 'compute': None, 'services': {'Tracking': {'endpoint': 'azureml://eastus2.api.azureml.ms/mlflow/v1.0/subscriptions/1a1e86ad-fe04-43a8-9dc4-0c907e547b71/resourceGroups/rg-dp100-labs/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-labs?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/careful_star_17zy9sfpgt?wsid=/subscriptions/1a1e86ad-fe04-43a8-9dc4-0c907e547b71/resourcegroups/rg-dp100-labs/workspaces/mlw-dp100-labs&tid=4617d4c8-9c8a-4f17-b20d-6258a331c40e', 'type': 'Studio'}}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    my_job,\n",
    "    experiment_name=\"hello-world-parallel-job\",\n",
    ")\n",
    "pipeline_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da555968-f916-45ca-b170-c38f14395ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
